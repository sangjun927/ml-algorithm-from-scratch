{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)\n",
    "\n",
    "Named Entity Recognition (NER) is an important  task in natural language processing. In this assignment you will implement a neural network model for NER.  In particular you will implement an approach called Sliding Window Neural Network. The dataset is composed of sentences. The dataframe already has each words parsed in one column and the corresponding label (entity) in the second column. We will build a \"window\" model, the idea on the window model is to use 5-word window to predict the name entity of the middle word. Here is the first observation in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/Genia4ERtask1.iob2\", sep=\"\\t\", header=None, names=[\"word\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IL-2</td>\n",
       "      <td>B-DNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gene</td>\n",
       "      <td>I-DNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>expression</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NF-kappa</td>\n",
       "      <td>B-protein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word      label\n",
       "0        IL-2      B-DNA\n",
       "1        gene      I-DNA\n",
       "2  expression          O\n",
       "3         and          O\n",
       "4    NF-kappa  B-protein"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_data = pd.read_csv(\"data/tiny.ner.train\", sep=\"\\t\", header=None, names=[\"word\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second observation is the 5 words starting with 'gene' and the label is the entity for the word 'and'. We have 5 features (categorical variables) which are words. We will use a word embedding to represent each value of the categorical features. For each observation, we concatenate the values of the 5 word embeddings for that observation. The vector of concatenated embeddings is feeded to a linear layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394040"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = int(data.shape[0]*0.8)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data.iloc[:N,].copy()\n",
    "valid_df = data.iloc[N:,].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((394040, 2), (98511, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word and label to index mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = label_encoding(train_df[\"word\"].values)\n",
    "label2index = label_encoding(train_df[\"label\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-DNA': 0,\n",
       " 'B-RNA': 1,\n",
       " 'B-cell_line': 2,\n",
       " 'B-cell_type': 3,\n",
       " 'B-protein': 4,\n",
       " 'I-DNA': 5,\n",
       " 'I-RNA': 6,\n",
       " 'I-cell_line': 7,\n",
       " 'I-cell_type': 8,\n",
       " 'I-protein': 9,\n",
       " 'O': 10}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_vocab2index = label_encoding(tiny_data[\"word\"].values)\n",
    "tiny_label2index = label_encoding(tiny_data[\"label\"].values)\n",
    "tiny_data_enc = dataset_encoding(tiny_data, tiny_vocab2index, tiny_label2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = np.array([17, 53, 31, 25, 44, 41, 32,  0, 11,  1])\n",
    "assert(np.array_equal(tiny_data_enc.iloc[30:40].word.values, actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_ds = NERDataset(tiny_data_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tiny_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([11., 30., 26., 18., 13.], dtype=float32), array(6))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = tiny_ds[0]\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = tiny_ds[0]\n",
    "assert(np.array_equal(x, np.array([11, 30, 26, 18, 13])))\n",
    "assert(y == 6)\n",
    "assert(len(tiny_ds) == 93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding datasets\n",
    "train_df_enc = dataset_encoding(train_df, vocab2index, label2index)\n",
    "valid_df_enc = dataset_encoding(valid_df, vocab2index, label2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating datasets\n",
    "train_ds =  NERDataset(train_df_enc)\n",
    "valid_ds = NERDataset(valid_df_enc)\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 10000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss  0.726 val loss 0.397 and accuracy 0.881\n",
      "train loss  0.313 val loss 0.331 and accuracy 0.898\n",
      "train loss  0.248 val loss 0.311 and accuracy 0.904\n",
      "train loss  0.216 val loss 0.307 and accuracy 0.906\n",
      "train loss  0.195 val loss 0.294 and accuracy 0.909\n",
      "train loss  0.179 val loss 0.305 and accuracy 0.908\n",
      "train loss  0.169 val loss 0.319 and accuracy 0.906\n",
      "train loss  0.161 val loss 0.308 and accuracy 0.909\n",
      "train loss  0.156 val loss 0.316 and accuracy 0.907\n",
      "train loss  0.151 val loss 0.324 and accuracy 0.907\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab2index)+1\n",
    "n_class = len(label2index)\n",
    "emb_size = 100\n",
    "\n",
    "model = NERModel(vocab_size, n_class, emb_size)\n",
    "optimizer = get_optimizer(model, lr = 0.01, wd = 1e-5)\n",
    "train_model(model, optimizer, train_dl, valid_dl, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss  0.133 val loss 0.313 and accuracy 0.910\n",
      "train loss  0.128 val loss 0.313 and accuracy 0.910\n",
      "train loss  0.126 val loss 0.312 and accuracy 0.910\n",
      "train loss  0.124 val loss 0.311 and accuracy 0.910\n",
      "train loss  0.123 val loss 0.316 and accuracy 0.909\n",
      "train loss  0.122 val loss 0.315 and accuracy 0.910\n",
      "train loss  0.121 val loss 0.316 and accuracy 0.910\n",
      "train loss  0.119 val loss 0.318 and accuracy 0.909\n",
      "train loss  0.119 val loss 0.316 and accuracy 0.910\n",
      "train loss  0.118 val loss 0.321 and accuracy 0.909\n"
     ]
    }
   ],
   "source": [
    "optimizer = get_optimizer(model, lr = 0.001, wd = 1e-5)\n",
    "train_model(model, optimizer, train_dl, valid_dl, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss, valid_acc = valid_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.32053950130939485, 0.9091739673322708)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_loss, valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(round(np.abs(valid_loss - 0.3),2) <= 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.abs(valid_loss - 0.3),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02053950130939486"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(valid_loss - 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.abs(valid_acc - 0.9) < 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
